import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,confusion_matrix,mean_squared_error,cohen_kappa_score,mean_absolute_error
import math

# Importing the dataset
dataset = pd.read_csv('C:/Users/FL_LPT-195/Downloads/diabetes.csv')
X = dataset.iloc[1:, :8].values
y = dataset.iloc[1:, -1].values



# Splitting the dataset into the Training set and Test set

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)


# Fitting Simple Linear Regression to the Training set

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

# Predicting the Test set results
y_pred = clf.predict(X_test)
conf_matrix=confusion_matrix(y_test,y_pred)
sum_conf_matrix=conf_matrix[0][0]+conf_matrix[0][1]+conf_matrix[1][0]+conf_matrix[1][1]
y_test_mean=np.mean(y_test)
print("accuracy:",accuracy_score(y_test,y_pred))
print("Correctly classified instances(%)",((conf_matrix[0][0]+conf_matrix[1][1])/sum_conf_matrix)*100)
print("Incorrectly classified instances(%)",((conf_matrix[0][1]+conf_matrix[1][0])/sum_conf_matrix)*100)
print("Kappa statistic",cohen_kappa_score(y_test,y_pred))
print("Mean absoulte error",mean_absolute_error(y_test,y_pred))
print("Root mean squared error",math.sqrt(mean_squared_error(y_test,y_pred)))

relative_abs_error=sum(abs(y_pred-y_test))/sum(abs(y_test_mean-y_test))
print("Relative absolute error(%)",relative_abs_error*100)

root_rel_sq_error=sum(np.sqrt(abs(y_pred-y_test)))/sum(np.sqrt(abs(y_test_mean-y_test)))
print("Root relative square error(%)",root_rel_sq_error*100)
